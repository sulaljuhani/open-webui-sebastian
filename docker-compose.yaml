services:
  open-webui:
    build:
      context: .
      dockerfile: Dockerfile
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}
    container_name: open-webui-sebastian
    volumes:
      - open-webui:/app/backend/data
    ports:
      - ${OPEN_WEBUI_PORT-3000}:8080
    environment:
      # Use existing Ollama container (via Docker network or host)
      - 'OLLAMA_BASE_URL=${OLLAMA_BASE_URL-http://ollama:11434}'
      - 'WEBUI_SECRET_KEY='
      - 'ENABLE_NOTES=false'
    extra_hosts:
      - host.docker.internal:host-gateway
    networks:
      - default
      - ai-stack-network
    restart: unless-stopped

networks:
  ai-stack-network:
    external: true
    name: ai-stack-network

volumes:
  open-webui: {}
